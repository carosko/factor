#!/usr/bin/env python
# encoding: utf-8
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
#
# The code is based on an original idea of Reinout van Weeren

import sys
import os
import numpy as np
import logging
import pickle
import factor
import factor.directions
import factor.parset
import factor.cluster
from factor.operations.field_ops import *
from factor.operations.facet_ops import *
from factor.lib.scheduler_mp import Scheduler
from factor.lib.direction import Direction


if __name__=='__main__':
    import optparse
    parser = optparse.OptionParser(usage='%prog [-v|-q] parset [default: factor.parset]',
            version='%%prog %s' % (factor._version.__version__))
    parser.add_option('-d', help='enable dry-run mode', action='store_true', default=False)
    parser.add_option('-q', help='enable quiet mode', action='store_true', default=False)
    parser.add_option('-v', help='enable verbose mode', action='store_true', default=False)
    (options, args) = parser.parse_args()

    if len(args) not in [0, 1]:
        opt.print_help()
        sys.exit()

    # Prepare logger
    if options.q:
        logging_level = 'warning'
    elif options.v:
        logging_level = 'debug'
    else:
        logging_level = 'info'
    factor._logging.set_level(logging_level)
    log = logging.getLogger('factor')

    # Prepare parset
    try:
        parset_file = args[0]
    except:
        parset_file = 'factor.parset'
    parset = factor.parset.parset_read(parset_file)
    parset['logging_level'] = logging_level

    # Prepare vis data
    bands = []
    from factor.lib.band import Band
    for ms in parset['mss']:
        band = Band(ms, parset['dir_working'])
        band.dirindparmdb = os.path.join(band.file, parset['parmdb_name'])
        if not os.path.exists(band.dirindparmdb):
            log.critical('Direction-independent instument parmdb not found '
                'for band {0}'.format(band.file))
            sys.exit(1)
        band.skymodel_dirindep = None
        msbase = os.path.basename(ms)
        if msbase in parset['ms_specific']:
            if 'init_skymodel' in parset['ms_specific'][msbase]:
                band.skymodel_dirindep = parset['ms_specific'][msbase]['init_skymodel']
        bands.append(band)

    # Check directions. First check for user-supplied file, then for Factor-generated
    # file from a previous run, then for parameters needed to generate it internally
    if 'directions_file' in parset:
        directions = factor.directions.directions_read(parset['directions_file'],
            parset['dir_working'])
    elif os.path.exists(os.path.join(parset['dir_working'], 'factor_directions.txt')):
        directions = factor.directions.directions_read(os.path.join(parset['dir_working'],
            'factor_directions.txt'), parset['dir_working'])
    else:
        dir_parset = parset['direction_specific']
        if 'flux_min_jy' not in dir_parset or \
            'size_max_arcmin' not in dir_parset or \
            'separation_max_arcmin' not in dir_parset:
                log.critical('If no directions file is specified, you must '
                    'give values for flux_min_Jy, size_max_arcmin, and '
                    'separation_max_arcmin')
                sys.exit(1)
        else:
            directions = None

    # Make direction object for the field
    field = Direction('field', bands[0].ra, bands[0].dec,
        factor_working_dir=parset['dir_working'])
    field.imsize_high_res = 6250 # TODO: calculate image size for each field
    field.imsize_low_res = 4800 # TODO: calculate image size for each field

    # Get clusterdesc and nodes
    cluster_parset = parset['cluster_specific']
    if 'clusterdesc_file' not in cluster_parset:
        parset['cluster_specific']['clusterdesc'] = 'local.clusterdesc'
    else:
        if cluster_parset['clusterdesc_file'].lower() == 'pbs':
            parset['cluster_specific']['clusterdesc'] = factor.cluster.make_pbs_clusterdesc()
        else:
            parset['cluster_specific']['clusterdesc'] = cluster_parset['clusterdesc_file']
    if not 'node_list' in cluster_parset:
        parset['cluster_specific']['node_list'] = factor.cluster.get_compute_nodes(
            parset['cluster_specific']['clusterdesc'])

    # Set up scheduler for operations (pipeline runs)
    scheduler = Scheduler(max_procs=len(parset['cluster_specific']['node_list']),
        dryrun=options.d)

    # Run initial sky model generation and create empty datasets. First check that
    # this operation is needed (only needed if band lacks an initial skymodel or
    # the SUBTRACTED_DATA_ALL column).
    bands_init_subtract = []
    for band in bands:
        if band.skymodel_dirindep is None or not band.has_sub_data:
            bands_init_subtract.append(band)
    if len(bands_init_subtract) > 0:
        op = InitSubtract(parset, bands_init_subtract, field)
        scheduler.run(op)
    else:
        log.info("Sky models found for all MS files. Skipping initial subtraction "
            "operation")

    # Prepare directions
    if directions is None:
        # Make directions from dir-indep sky models using flux and size parameters
        log.info("No directions file given. Selecting directions internally...")
        parset['directions_file'] = factor.directions.make_directions_file_from_skymodel(bands,
        	parset['direction_specific']['flux_min_jy'],
        	parset['direction_specific']['size_max_arcmin'],
        	parset['direction_specific']['separation_max_arcmin'],
        	directions_max_num=parset['direction_specific']['max_num'],
        	interactive=parset['interactive'])
        directions = factor.directions.directions_read(parset['directions_file'],
            parset['dir_working'])

    # Load polygons from previous run if possible
    polys_file = os.path.join(parset['dir_working'], 'regions', 'factor_facets.pkl')
    if os.path.exists(polys_file):
        with open(polys_file, 'r') as f:
            polys, widths = pickle.load(f)
    else:
        polys, widths = factor.directions.thiessen(directions,
            check_edges=parset['direction_specific']['check_edges'])
        with open(polys_file, 'wb') as f:
            pickle.dump([polys, widths], f)

    # Set various direction attributes
    for i, direction in enumerate(directions):
        direction.vertices = polys[i]
        direction.width = widths[i]
        reg_file = os.path.join(parset['dir_working'], 'regions', direction.name+'.rgn')
        factor.directions.make_region_file(direction.vertices, reg_file)
        direction.reg = reg_file

        # For WSClean, set number of bands
        direction.nbands = len(bands)
        direction.nchannels = np.int(np.ceil(np.float(direction.nbands/
                    np.float(5))))

        # Set field center
        direction.field_ra = field.ra
        direction.field_dec = field.dec

        # Save direction state
        direction.save_state()

    # Make DS9 region files so user can see facets, etc.
    ds9_facet_reg_file = os.path.join(parset['dir_working'], 'regions', 'facets_ds9.reg')
    factor.directions.make_ds9_region_file(directions, ds9_facet_reg_file)
    ds9_calimage_reg_file = os.path.join(parset['dir_working'], 'regions', 'calimages_ds9.reg')
    factor.directions.make_ds9_calimage_file(directions, ds9_calimage_reg_file)

    # Check with user
    if parset['interactive']:
        print("Facet and DDE calibrator regions saved. Please check that they "
            "are OK before continuing.")
        prompt = "Continue processing (y/n)? "
        answ = raw_input(prompt)
        while answ.lower() not in  ['y', 'n', 'yes', 'no']:
            answ = raw_input(prompt)
        if answ.lower() in ['n', 'no']:
            self.log.info('Exiting...')
            sys.exit()

    # Select subset of directions to process
    if 'ndir' in parset['direction_specific']:
        if parset['direction_specific']['ndir'] > 0 and \
            parset['direction_specific']['ndir'] <= len(directions):
            directions = directions[:parset['direction_specific']['ndir']]

    direction_groups = factor.directions.group_directions(directions,
        one_at_a_time=parset['direction_specific']['one_at_a_time'],
        n_per_grouping=parset['direction_specific']['groupings'])

    # Iterate over direction groups
    first_pass = True
    for direction_group in direction_groups:
        log.info('Processing {0} direction(s) in parallel in this group'.format(
            len(direction_group)))

        # Divide up the nodes among the directions
        node_list = parset['cluster_specific']['node_list']
        if len(direction_group) >= len(node_list):
            for i in range(len(direction_group)-len(node_list)):
                node_list.append(node_list[i])
            hosts = [[n] for n in node_list]
        else:
            parts = len(direction_group)
            hosts = [node_list[i*len(node_list)//parts:
                (i+1)*len(node_list)//parts] for i in range(parts)]
        for d, h in zip(direction_group, hosts):
            d.hosts = h
            d.save_state()

        # Add calibrator(s) to empty datasets. These operations
        # must be done in series
        ops = [FacetAdd(parset, bands, d) for d in direction_group]
        for op in ops:
            scheduler.run(op)

        # Setup up facet(s) for selfcal of calibrator
        ops = [FacetSetup(parset, bands, d) for d in direction_group]
        scheduler.run(ops)

        # Do selfcal on calibrator only
        ops = [FacetSelfcal(parset, bands, d) for d in direction_group]
        scheduler.run(ops)

        # Make image of all sources in the facet(s) and get final model(s)
        ops = [FacetImage(parset, bands, d) for d in direction_group]
        scheduler.run(ops)

        # Subtract model(s) from empty facet datasets and image to check if OK
        ops = [FacetCheck(parset, bands, d) for d in direction_group]
        scheduler.run(ops)

        # Subtract final model(s) from empty field datasets. These operations
        # must be done in series and only on the directions that passed the
        # selfcal check. Also, after this operation is complete for any
        # direction, set flag to indicate all subsequent directions should use
        # new subtracted data column
        direction_group_ok = [d in direction_group if d.selfcal_ok]
        if first_pass:
            if len(direction_group_ok) > 0:
                # Only use new data if at least one direction is OK
                for i, d in enumerate(directions):
                    # Set flag for *all* directions except first one
                    if i > 0:
                        d.use_new_sub_data = True
                first_pass = False
        else:
            for d in direction_group_ok:
                d.use_new_sub_data = True
        ops = [FacetSub(parset, bands, d) for d in direction_group if d.selfcal_ok]
        for op in ops:
            scheduler.run(op)

        # Lastly, stop Factor if selfcal for any direction in this group failed
        for d in direction_group:
            all_good = True
            if not d.selfcal_ok:
                log.error('Selfcal failed for direction {0}. Please check '
                    'the settings for this direction.'.format(d.name))
                d.reset_state()
                all_good = False
            else:
                d.save_state()
        if not all_good:
            sys.exit(1)

        # Clean up files
        for d in direction_group:
            d.cleanup()

    # Make final facet images (from final empty datasets) if desired
    dirs_to_image = [d for d in directions if d.make_final_image]
    if len(dirs_to_image) > 0:
        ops = [FacetAddAllFinal(parset, bands, d) for d in dirs_to_image]
        for op in ops:
            scheduler.run(op)
        ops = [FacetImageFinal(parset, bands, d) for d in dirs_to_image]
        scheduler.run(ops)

    # Mosaic the final facet images together
    if parset['make_mosaic']:
        op = MakeMosaic(parset, directions)
        scheduler.run(op)

    log.info("Factor has finished :)")


