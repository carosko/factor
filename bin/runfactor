#!/usr/bin/env python
# encoding: utf-8
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
#
# The code is based on an original idea of Reinout van Weeren

import sys
import os
import numpy as np
import logging
import pickle
import factor
import factor.directions
import factor.parset
import factor.cluster
from factor.operations.field_ops import *
from factor.operations.facet_ops import *


if __name__=='__main__':
    import optparse
    opt = optparse.OptionParser(usage='%prog [-v|-q] parset [default: factor.parset]',
            version='%%prog %s' % (factor._version.__version__))
    opt.add_option('-q', help='enable quiet mode', action='store_true', default=False)
    opt.add_option('-v', help='enable verbose mode', action='store_true', default=False)
    (options, args) = opt.parse_args()

    if len(args) not in [0, 1]:
        opt.print_help()
        sys.exit()

    # Prepare logger
    if options.q:
        logging_level = 'warning'
    elif options.v:
        logging_level = 'debug'
    else:
        logging_level = 'info'
    factor._logging.set_level(logging_level)
    log = logging.getLogger('factor')

    # Prepare parset
    try:
        parset_file = args[0]
    except:
        parset_file = 'factor.parset'
    parset = factor.parset.parset_read(parset_file)
    parset['logging_level'] = logging_level

    # Prepare vis data
    bands = []
    from factor.lib.band import Band
    for ms in parset['mss']:
        band = Band(ms, parset['dir_working'])
        band.dirindparmdb = os.path.join(band.file, parset['parmdb_name'])
        if not os.path.exists(band.dirindparmdb):
            log.critical('Direction-independent instument parmdb not found '
                'for band {0}'.format(band.file))
            sys.exit(1)
        band.skymodel_dirindep = None
        msbase = os.path.basename(ms)
        if msbase in parset['ms_specific']:
            if 'init_skymodel' in parset['ms_specific'][msbase]:
                band.skymodel_dirindep = parset['ms_specific'][msbase]['init_skymodel']
        bands.append(band)

    # Check directions. First check for user-supplied file, then for Factor-generated
    # file from a previous run, then for parameters needed to generate it internally
    if 'directions_file' in parset:
        directions = factor.directions.directions_read(parset['directions_file'],
            parset['dir_working'])
    elif os.path.exists(os.path.join(parset['dir_working'], 'factor_directions.txt')):
        directions = factor.directions.directions_read(os.path.join(parset['dir_working'],
            'factor_directions.txt'), parset['dir_working'])
    else:
        dir_parset = parset['direction_specific']
        if 'flux_min_jy' not in dir_parset or \
            'size_max_arcmin' not in dir_parset or \
            'separation_max_arcmin' not in dir_parset:
                log.critical('If no directions file is specified, you must '
                    'give values for flux_min_Jy, size_max_arcmin, and '
                    'separation_max_arcmin')
                sys.exit(1)
        else:
            directions = None

    # Get clusterdesc and nodes
    cluster_parset = parset['cluster_specific']
    if 'clusterdesc_file' not in cluster_parset:
        parset['cluster_specific']['clusterdesc'] = 'local.clusterdesc'
    else:
        if cluster_parset['clusterdesc_file'].lower() == 'pbs':
            parset['cluster_specific']['clusterdesc'] = factor.cluster.make_pbs_clusterdesc()
        else:
            parset['cluster_specific']['clusterdesc'] = cluster_parset['clusterdesc_file']
    if not 'node_list' in cluster_parset:
        parset['cluster_specific']['node_list'] = factor.cluster.get_compute_nodes(
            parset['cluster_specific']['clusterdesc'])

    # Run initial sky model generation and create empty datasets. First check that
    # this operation is needed (only needed if band lacks an initial skymodel or
    # the SUBTRACTED_DATA_ALL column).
    bands_init_subtract = []
    for band in bands:
        if band.skymodel_dirindep is None or not band.has_sub_data:
            bands_init_subtract.append(band)
    if len(bands_init_subtract) > 0:
        op = InitSubtract(parset, bands_init_subtract)
        op.run()
    else:
        log.info("Sky models found for all MS files. Skipping initial subtraction "
            "operation")

    # Prepare directions
    if directions is None:
        # Make directions from dir-indep sky models using flux and size parameters
        log.info("No directions file given. Selecting directions internally...")
        parset['directions_file'] = factor.directions.make_directions_file_from_skymodel(bands,
        	parset['direction_specific']['flux_min_jy'],
        	parset['direction_specific']['size_max_arcmin'],
        	parset['direction_specific']['separation_max_arcmin'],
        	directions_max_num=parset['direction_specific']['max_num'],
        	interactive=parset['interactive'])
        directions = factor.directions.directions_read(parset['directions_file'],
            parset['dir_working'])

    # Load polygons from previous run if possible
    polys_file = os.path.join(parset['dir_working'], 'regions', 'factor_facets.pkl')
    if os.path.exists(polys_file):
        with open(polys_file, 'r') as f:
            polys, widths = pickle.load(f)
    else:
        polys, widths = factor.directions.thiessen(directions,
            check_edges=parset['direction_specific']['check_edges'])
        with open(polys_file, 'wb') as f:
            pickle.dump([polys, widths], f)

    # Store polygons and make CASA regions
    for i, direction in enumerate(directions):
        direction.vertices = polys[i]
        direction.width = widths[i]
        reg_file = os.path.join(parset['dir_working'], 'regions', direction.name+'.reg')
        factor.directions.make_region_file(direction.vertices, reg_file)
        direction.reg = reg_file

    # For WSClean, set number of bands
    for direction in directions:
        direction.nbands = len(bands)
        direction.nchannels = np.int(np.ceil(np.float(direction.nbands/
                    np.float(5)))) # for WSClean

    # Make DS9 region files
    ds9_facet_reg_file = os.path.join(parset['dir_working'], 'regions', 'facets_ds9.reg')
    factor.directions.make_ds9_region_file(directions, ds9_facet_reg_file)
    ds9_calimage_reg_file = os.path.join(parset['dir_working'], 'regions', 'calimages_ds9.reg')
    factor.directions.make_ds9_calimage_file(directions, ds9_calimage_reg_file)

    # Check with user
    if parset['interactive']:
        print("Facet and DDE calibrator regions saved. Please check that they "
            "are OK before continuing.")
        prompt = "Continue processing (y/n)? "
        answ = raw_input(prompt)
        while answ.lower() not in  ['y', 'n', 'yes', 'no']:
            answ = raw_input(prompt)
        if answ.lower() in ['n', 'no']:
            self.log.info('Exiting...')
            sys.exit()

    # Select subset of directions to process
    if 'ndir' in parset['direction_specific']:
        if parset['direction_specific']['ndir'] > 0 and \
            parset['direction_specific']['ndir'] <= len(directions):
            directions = directions[:parset['direction_specific']['ndir']]

    direction_groups = factor.directions.group_directions(directions,
        one_at_a_time=parset['direction_specific']['one_at_a_time'],
        n_per_grouping=parset['direction_specific']['groupings'])

    # Iterate over direction groups
    for direction_group in direction_groups:
        log.info('Processing {0} direction(s) in parallel'.format(
            len(direction_group)))

        # Add calibrator(s) to empty datasets. These operations
        # must be done in series
        ops = [FacetAdd(parset, bands, d) for d in direction_group]
        for op in ops:
            op.run()

        # Setup up facet(s) for selfcal of calibrator
        op = FacetSetup(parset, bands, direction_group)
        op.run()

        # Do selfcal on calibrator only
        op = FacetSelfcal(parset, bands, direction_group)
        op.run()

        # Make image of all sources in the facet(s) and get final model(s)
        op = FacetImage(parset, bands, direction_group)
        op.run()

        # Subtract model(s) from empty facet datasets and image to check if OK
        op = FacetCheck(parset, bands, direction_group)
        op.run()

        # Subtract final model(s) from empty field datasets. These operations
        # must be done in series
        ops = [FacetSub(parset, bands, d) for d in direction_group if d.selfcal_ok]
        for op in ops:
            op.run()

        # Lastly, stop Factor if selfcal for any direction in this group failed
        for d in direction_group:
            all_good = True
            if not d.selfcal_ok:
                log.error('Selfcal failed for direction {0}. Please check '
                    'the settings for this direction.'.format(d.name))
                d.reset_state()
                all_good = False
        if not all_good:
            sys.exit(1)

    # Make final facet images (from final empty datasets) if desired
    dirs_to_image = [d for d in directions if d.make_final_image]
    if len(dirs_to_image) > 0:
        ops = [FacetAddAllFinal(parset, bands, d) for d in dirs_to_image]
        for op in ops:
            op.run()
        op = FacetImageFinal(parset, bands, dirs_to_image)
        op.run()

    # Mosaic the final facet images together
    if parset['make_mosaic']:
        op = MakeMosaic(parset, directions)
        op.run()

    log.info("Factor has finished :)")


