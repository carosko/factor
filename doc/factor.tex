\documentclass[structabstract]{article}
\usepackage[varg]{txfonts}
% include packages
%\usepackage[dvips]{graphicx}
\usepackage{url}
\usepackage[breaklinks=true]{hyperref}
\usepackage{twoopt}
\usepackage{natbib}
\bibpunct{(}{)}{;}{a}{}{,}%% natbib format for A&A and ApJ
\usepackage{ctable}
\usepackage{multirow}
\usepackage[farskip=0pt]{subfig}

\setlength{\textwidth}{6.5in}
\setlength{\textheight}{9in}
\setlength{\topmargin}{-0.0625in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\headheight}{0in}
\setlength{\headsep}{0in}
\setlength{\hoffset}{0in}
\setlength{\voffset}{0in}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%CUTCUTCUT

%\svnInfo $Id: bbs.tex 12951 2014-03-08 18:40:31Z dijkema $
\section[Factor: Facet Calibration for LOFAR]{Factor: Facet Calibration for
LOFAR\footnote{This section is maintained by David Rafferty
({\tt drafferty@hs.uni-hamburg.de}).}}
\label{factor}

Factor is a Python package that allows for the production of wide-field HBA
LOFAR images using the facet calibration scheme described in van Weeren et al.\
(2015). Note that Factor is still beta software. Please report bugs to
{\tt drafferty@hs.uni-hamburg.de}. To initialize your environment for Factor,
users on CEP2 and CEP3 should run the following commands:
\begin{verbatim}
use Lofar
source ~rafferty/init_factor
use Casa
use Pythonlibs
\end{verbatim}

%-----------------------------------------------------------
\subsection{Usage}
\label{factor:usage}

Factor is run from the command-line with the {\tt runfactor} executable as
follows:
\begin{verbatim}
Usage: runfactor [-v|-q|-d] <parset>

Options:
  --version   show program's version number and exit
  -h, --help  show this help message and exit
  -q          enable quiet mode
  -v          enable verbose mode
  -d          enable dry-run mode
\end{verbatim}
The parset specifies the parameters of the run. These are described in the next
sections.

\subsubsection{Quick-start}
\label{factor:quick-start}
Below is a quick-start quide to a typical run.

\begin{enumerate}
\item Collect the input bands (described in Section \ref{factor:data}) in a
single directory. The MS names can be anything but must end in ``.MS'' or
``.ms'':
\begin{verbatim}
[/data/factor_input]$ ls
band1.MS         band2.ms         A.MS         b.ms
\end{verbatim}
\item Edit the Factor parset (described in Section \ref{factor:parset}) to fit
your reduction and computing resources. For example, the parset for a single
machine could be:
\begin{verbatim}
[/data]$ more factor.parset
[global]
dir_working = /data/factor_output
dir_ms = /data/factor_input
piperoot = /software/local/genericpipeline
parmdb_name = instrument_ap_smoothed
iteractive = True

[directions]
flux_min_jy = 0.1
size_max_arcmin = 3.0
separation_max_arcmin = 7.5
max_num = 30
groupings = 1:0
check_edges = True

[cluster]
ncpu = 5
\end{verbatim}
\item Run the reduction:
\begin{verbatim}
[/data]$ runfactor factor.parset
\end{verbatim}
\end{enumerate}

%-----------------------------------------------------------
\subsection{Parset}
\label{factor:parset}

Below is an template parset that shows the available parameters. Note that the
parameters are grouped by sections (denoted by headings such as {\tt [global]},
{\tt [directions]}, etc.). Required parameters are noted.

\begin{verbatim}
[global]
# LOFAR installation root directories. If not given, they will be determined
# from the environment
lofarroot = /lofar/build/gnu_opt/installed
lofarpythonpath = /lofar/build/gnu_opt/installed/lib/python2.7/dist-packages

# Full path to Generic Pipeline root directory (required)
piperoot = /path/to/genericpipeline

# Full path to working dir - other paths are relative to this (required)
dir_working = /data/wdir

# Full path to directory containing selfcaled bands, will be scanned for all .MS
# and .ms files (required). Note that these files will be modified by Factor, so
# please keep a copy of these data elsewhere
dir_ms = /data/bands

# Parmdb name for dir-indep. selfcal solutions (stored inside the input
# band measurement sets, so path should be relative to those; default =
# instrument)
parmdb_name = instrument_ap_smoothed

# Make final mosaic (default = True)
make_mosaic = False

# Use interactive mode (default = False). Factor will ask for confirmation
# of internally derived DDE calibrators and facets
interactive = False

# Use chgcenter to minimize number of w planes (default = False). Note that a
# copy of the full dataset will be made (as chgcentre modifies the data)
use_chgcentre = False


[directions]
# Full path to file containing calibrator directions. If not given, directions
# are selected internally using the flux and size cuts below
directions_file = /data/directions.txt

# Check whether any sources from the initial subtract sky model fall on facet
# edges. If any are found, the facet regions are adjusted to avoid them (default
# is False)
check_edges = False

# Flux and size cuts for selecting directions internally (min flux, max size
# of a source, and max separation between sources below which they are grouped
# into one direction; required if no directions_file is given)
flux_min_Jy = 0.1
size_max_arcmin = 3.0
separation_max_arcmin = 6.0

# The number of internally derived directions can be limited to a maximum number
# of directions if desired (default = all)
max_num = 50

# Total number of directions to process (default = all)
ndir = 10

# Grouping of directions into groups that are processed in parallel, defined as
# grouping:n_total_per_grouping. For example, groupings = 1:5, 4:0 means two
# groupings are used, with the first 5 directions put into groups of one (i.e.,
# each direction processed in series) and the rest of the directions divided
# into groups of 4 (i.e., 4 directions processed in parallel). Shuffling is done
# between neighboring groups to achieve the largest min separation. Default is
# one at a time (i.e., groupings = 1:0)
groupings = 1:5, 4:0


[cluster]
# Full path to cluster description file. Use clusterdesc_file = PBS to use the
# PBS / torque reserved nodes. If not given, the clusterdesc file for a single
# (i.e., local) node is used
clusterdesc_file = PBS

# Maximum number of CPUs per node to use (default = all)
ncpu = 6

# Number of directions to process in parallel on each node (default = 1). If
# directions are split into groups to be processed in parallel (with the
# groupings parameter), this parameter controls how many directions are run
# simultaneously on a single node. Note that the number of CPUs (set with the
# ncpu parameter) will be divided among the directions on each node
ndir_per_node = 1


# MS-specific parameters (optional)
[ms1.ms]
init_skymodel = /data/ms1.sky
param1 = 123
param2 = 123

[ms2.ms]
init_skymodel = /data/ms2.sky
param1 = 123
param2 = 123
\end{verbatim}


%-----------------------------------------------------------
\subsection{Data Preparation}
\label{factor:data}

The input data must be have the average amplitude scale set and average clock
offsets removed. Futhermore, the LOFAR beam towards the phase center should be
removed. The data should then undergo direction-independent, phase-only self
calibration, and the resulting solutions must be provided to Factor. If desired,
all sources can be subtracted before Factor is run, thereby allowing one to skip
the initial subtraction operation. These steps can be automated using the facet
calibration preparation pipeline.

%-----------------------------------------------------------
\subsection{Directions}
\label{factor:directions}

The directions for which DDE calibration is performed can be selected
automatically in Factor or specified in a file. The format of the file is as
follows:

\begin{verbatim}
# This is an example directions file for Factor.
#
# Directions should be sorted in order of reduction (e.g., bright to faint).
#
# name position atrous_do mscale_field_do cal_imsize solint_ph solint_amp
# field_imsize dynamic_range region_selfcal region_field peel_skymodel
# outlier_source

s1  14h41m01.884,+35d30m31.52 False False 512  1 30  5600 LD empty empty    s1.skymodel True
s2  14h38m29.584,+33d57m37.82 False False 1024 1 30  5600 LD empty empty    empty       False
s25 14h21m07.482,+35d35m22.87 False False 1280 2 240 5600 LD empty s25.rgn  empty       False
\end{verbatim}
This file should be specified in the parset file as the {\tt directions\_file}
parameter.

If no {\tt directions\_file} is given, the directions and their order of
processing are determined internally using the flux, size, and separation limits
specified in the parset as follows. First, the initial apparent-flux
clean-component (CC) skymodels (either given as input in the parset or generated
by the initial subtraction operation) are grouped by LSMTool using the
thresholding algorithm. These grouped patches of CCs are then filtered to meet
the specified flux and size limits ({\tt flux\_min\_Jy} and {\tt
size\_max\_arcmin}, respectively) and nearby patches are merged (specified by
{\tt separation\_max\_arcmin}). The resulting patches are then sorted by
apparent flux at the lowest available frequency (from bright to faint), and the
final {\tt directions\_file} is written to the file {\tt
factor\_directions.txt} in the working directory.

Lastly, one can specify that more than one direction be processed in parallel
with the groupings parameter. The groupings parameter specifies the grouping
level (the number of directions to process simultaneously) and the total number
of directions at each grouping level. For example, {\tt groupings = 1:5, 4:0}
means two groupings are used, with the first 5 directions put into groups of one
(i.e., the directions are processed in series) and the rest of the directions
divided into groups of 4 (i.e., 4 directions processed in parallel). Shuffling
is done between neighboring groups to achieve the largest minimum separation
between directions in the groups. This sorting attempts to minimize the effects
that any artifacts from one direction might have on the other simultaneously
processed directions.


%-----------------------------------------------------------
\subsection{Parallelization}
\label{factor:parallel}

Factor has been designed to run as much as possible in a parallel manner. To
this end, support is present for distributing the reduction over the processors
and nodes of a compute cluster. To use Factor on a single computer, no setup is
necessary beyond specifying the maximum number of CPUs to use. To use Factor on
multiple nodes of a compute cluster, the required setup depends on the cluster
layout (distributed vs. shared file system) and scheduling system (if any), as
described in the following sections.

\subsubsection{Cluster without a scheduler}
For use on a cluster that does not use a scheduler to assign nodes to the user,
such as CEP2 and CEP3, you must provide a LOFAR pipeline cluster description
file that tells Factor which nodes are available. An example of such a file is
shown below.

\begin{verbatim}
ClusterName = MyCEP3
Compute.Nodes = [lof021, lof022]
\end{verbatim}

\subsubsection{Cluster with Torque / PBS }
For use on a cluster that uses torque and PBS, you can set {\tt clusterdesc =
PBS}. Factor will then automatically determine the nodes for which you have a
PBS reservation and use them. Note that you must ask for all the nodes you need
in a single PBS script (e.g., to use 6 nodes, with {\tt \#PBS -l
nodes=6:ppn=6}), so that all nodes are available for the full Factor run. An
example PBS script is shown below.

\begin{verbatim}
#!/bin/bash
#PBS -N Factor
#PBS -l walltime=100:00:00
#PBS -l nodes=6:ppn=6
#PBS -j oe
#PBS -o output-$PBS_JOBNAME-$PBS_JOBID
cd $PBS_O_WORKDIR
source /home/sttf201/init-lofar.sh
runfactor factor.parset
\end{verbatim}

\subsubsection{Cluster with a shared file system}
Factor works by default on a compute cluster with a shared file system.

\subsubsection{Cluster with a distributed file system}
Factor does not yet work on multiple nodes with a distributed file system (such
as CEP2 and CEP3). It does work on a single node of such a system.
%For use on a cluster with a distributed file system (such as CEP2 and CEP3), set
%{\tt distribute = True}. Factor will then synchronize files between the
%available nodes. Note that all data will be mirrored on each node, so one must
%ensure that all nodes have sufficient disk space. Additionally, the local disk
%must have the same name on each node.


%-----------------------------------------------------------
\subsection{Resuming}
\label{factor:resuming}

Due to the potentially long run times and the consequent non-negligible chance
of some unforeseen failure occurring, Factor has been designed to allow easy
resumption of a reduction from a saved state and will skip over any steps that
were successfully completed previously. In this way, one can quickly resume a
reduction that was halted (either by the user or due to some problem) by simply
re-running Factor with the same parset.

For example, one can specify that only the first 5 directions be processed.
Once these directions are done, Factor will exit. One can then alter the parset
and specify that 10 directions should be done. Upon restarting, Factor will skip
over the first 5 directions and start with the 6th one (and ending with the 10th
one).


%-----------------------------------------------------------
\subsection{Structure}
\label{factor:structure}

Factor is structured based on operations and actions. An operation is composed
of a sequence of actions. For example, the initial subtraction operation
(denoted {\tt initsubtract}) performs the following actions: image at high resolution,
make a sky model, subtract the sky model, average, image and low resolution,
make another sky model, and finally subtract the second sky model. Operations
divide the reduction into logical groupings of actions as follows.

\begin{description}
\item[{\tt initsubtract}] Performs the initial imaging and subtraction of sources to
create ``source-free'' datasets. This operation may be skipped if sky models are
specified for each band in the parset and the {\tt SUBTRACTED\_DATA\_ALL} column
is present in all the bands.
\item[{\tt facetadd}] For each direction, the facet sources are added to the
``source-free'' datasets. The data are then phase shifted to the appropriate
coordinates.
\item[{\tt facetselcal}] The direction-independent calibration is applied, and
the bands are concatenated and averaged. Selfcalibration is then performed on
one or more directions, using two rounds of phase-only calibration followed by
two rounds of fast-phase and slow-amplitude calibration. For each direction, all
sources in the facet are added to the ``source-free'' datasets. The data are
then phase shifted to the appropriate coordinates. The direction-dependent
calibration is applied, and the bands are concatenated and averaged. The entire
facet is then imaged, producing a final model of the facet sources.
\item[{\tt facetsub}] The final model is subtracted, producing improved
``source-free'' datasets.
\end{description}

The facet operations are repeated for each direction. The facetselfcal operation
can run on multiple directions simultaneously. After each action finishes, the
saved state is updated, allowing for resumption of steps at the granularity of
the actions in a given operation.

The results of the processing are stored in the {\tt results} directory in the
working directory by type. Inside these subdirectories, results are organized by
operation and dirrection. For example, for a direction named ``dir1'', the
results produced during self calibration are stored in {{\tt
results/facetselfcal/dir1/}.

\end{document}
